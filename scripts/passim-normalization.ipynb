{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFPexfZ9SDOf",
        "outputId": "4097bd55-060d-4d8d-a1b9-136443f5c4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-17-jdk > /dev/null 2>&1\n",
        "!update-alternatives --set java /usr/lib/jvm/java-17-openjdk-amd64/bin/java > /dev/null 2>&1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_IM-Sh7Srew",
        "outputId": "a1231c30-99f9-49ab-9a16-492926e963af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/dasmiq/passim.git -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugEoD-rDXexD",
        "outputId": "940cce50-4bba-4938-e3f0-a80b269cc8e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for passim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output"
      ],
      "metadata": {
        "id": "c-Bp6Sg8vCLU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import time\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "tar_path = '/content/drive/MyDrive/passim-thesis/passim-data.tar.gz'\n",
        "extract_to = '/content/data'\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with tarfile.open(tar_path, 'r:gz') as tar:\n",
        "    tar.extractall(extract_to)\n",
        "\n",
        "# List extracted files\n",
        "print(\"\\nExtracted files:\")\n",
        "for root, dirs, files in os.walk(extract_to):\n",
        "    for file in files:\n",
        "        if file.endswith('.json'):\n",
        "            filepath = os.path.join(root, file)\n",
        "            size_mb = os.path.getsize(filepath) / (1024*1024)\n",
        "            print(f\"  {filepath} ({size_mb:.1f} MB)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZpX5OrucCsz",
        "outputId": "3956a6bf-de03-4b6e-be31-b66848a96969"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1200178388.py:13: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(extract_to)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted files:\n",
            "  /content/data/bullinger-letters.json (37.0 MB)\n",
            "  /content/data/patristic-sources.json (263.6 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_latin(text):\n",
        "    \"\"\"\n",
        "    Simple but effective Latin text normalization\n",
        "    Fixes the j/i bug and standardizes orthography\n",
        "    \"\"\"\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Orthographic normalization\n",
        "    text = text.replace('j', 'i')\n",
        "    text = text.replace('J', 'I')\n",
        "    text = text.replace('æ', 'ae')\n",
        "    text = text.replace('Æ', 'ae')\n",
        "    text = text.replace('œ', 'oe')\n",
        "    text = text.replace('Œ', 'oe')\n",
        "\n",
        "    # Remove quotes and punctuation\n",
        "    text = re.sub(r'[«»\"\"„‟]', '', text)  # Remove quotes\n",
        "    text = re.sub(r'[;:,\\.\\!\\?\\(\\)\\[\\]\\{\\}]', ' ', text)  # Replace punctuation with space\n",
        "\n",
        "    # Normalize whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Test the function\n",
        "test = \"Videmus duplicem statum non confusum, sed conjunctum\"\n",
        "print(f\"\\nTest normalization:\")\n",
        "print(f\"  Original: {test}\")\n",
        "print(f\"  Normalized: {normalize_latin(test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Llu1tGFSf1",
        "outputId": "613cc4e4-d2be-4b54-d2a1-1e03b927c028"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test normalization:\n",
            "  Original: Videmus duplicem statum non confusum, sed conjunctum\n",
            "  Normalized: videmus duplicem statum non confusum sed coniunctum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bullinger_input = f'{extract_to}/bullinger-letters.json'\n",
        "bullinger_output = '/content/bullinger-normalized.json'\n",
        "\n",
        "start = time.time()\n",
        "processed = 0\n",
        "\n",
        "with open(bullinger_input, 'r', encoding='utf-8') as f_in, \\\n",
        "     open(bullinger_output, 'w', encoding='utf-8') as f_out:\n",
        "\n",
        "    for line in f_in:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        doc = json.loads(line)\n",
        "\n",
        "        if 'text' in doc:\n",
        "            doc['text'] = normalize_latin(doc['text'])\n",
        "\n",
        "        doc['corpus'] = 'bullinger'\n",
        "\n",
        "        f_out.write(json.dumps(doc, ensure_ascii=False) + '\\n')\n",
        "        processed += 1\n",
        "\n",
        "        if processed % 1000 == 0:\n",
        "            elapsed = time.time() - start\n",
        "            rate = processed / elapsed\n",
        "            print(f\"  {processed:,} processed | {rate:.1f} docs/sec\")\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(f\"Bullinger complete: {processed:,} documents in {elapsed:.1f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CkqGrmGFdxs",
        "outputId": "2453f57b-7e5b-4d3b-c1c8-714ac5f57cb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1,000 processed | 2046.4 docs/sec\n",
            "  2,000 processed | 1882.6 docs/sec\n",
            "  3,000 processed | 1779.3 docs/sec\n",
            "  4,000 processed | 1482.4 docs/sec\n",
            "  5,000 processed | 1541.7 docs/sec\n",
            "  6,000 processed | 1531.5 docs/sec\n",
            "  7,000 processed | 1522.6 docs/sec\n",
            "  8,000 processed | 1543.3 docs/sec\n",
            "  9,000 processed | 1606.7 docs/sec\n",
            "  10,000 processed | 1709.1 docs/sec\n",
            "  11,000 processed | 1809.6 docs/sec\n",
            "  12,000 processed | 1895.6 docs/sec\n",
            "  13,000 processed | 1973.9 docs/sec\n",
            "Bullinger complete: 13,114 documents in 6.6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patristic_input = f'{extract_to}/patristic-sources.json'\n",
        "patristic_output = '/content/patristic-normalized.json'\n",
        "\n",
        "start = time.time()\n",
        "processed = 0\n",
        "\n",
        "with open(patristic_input, 'r', encoding='utf-8') as f_in, \\\n",
        "     open(patristic_output, 'w', encoding='utf-8') as f_out:\n",
        "\n",
        "    for line in f_in:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        doc = json.loads(line)\n",
        "\n",
        "        if 'text' in doc:\n",
        "            doc['text'] = normalize_latin(doc['text'])\n",
        "\n",
        "        doc['corpus'] = 'patristic'\n",
        "\n",
        "        f_out.write(json.dumps(doc, ensure_ascii=False) + '\\n')\n",
        "        processed += 1\n",
        "\n",
        "        if processed % 5000 == 0:\n",
        "            elapsed = time.time() - start\n",
        "            rate = processed / elapsed\n",
        "            remaining = (115655 - processed) / rate / 60  # Approximate\n",
        "            print(f\"  {processed:,} processed | {rate:.1f} docs/sec | ~{remaining:.1f}min remaining\")\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(f\"Patristic complete: {processed:,} documents in {elapsed:.1f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOgL7rW6FYkW",
        "outputId": "119503c7-5689-49f0-d982-e1dc82c83800"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5,000 processed | 5894.5 docs/sec | ~0.3min remaining\n",
            "  10,000 processed | 6107.5 docs/sec | ~0.3min remaining\n",
            "  15,000 processed | 6260.7 docs/sec | ~0.3min remaining\n",
            "  20,000 processed | 6347.6 docs/sec | ~0.3min remaining\n",
            "  25,000 processed | 6348.6 docs/sec | ~0.2min remaining\n",
            "  30,000 processed | 6400.3 docs/sec | ~0.2min remaining\n",
            "  35,000 processed | 6379.1 docs/sec | ~0.2min remaining\n",
            "  40,000 processed | 5605.9 docs/sec | ~0.2min remaining\n",
            "  45,000 processed | 4367.9 docs/sec | ~0.3min remaining\n",
            "  50,000 processed | 4466.5 docs/sec | ~0.2min remaining\n",
            "  55,000 processed | 4594.3 docs/sec | ~0.2min remaining\n",
            "  60,000 processed | 4695.9 docs/sec | ~0.2min remaining\n",
            "  65,000 processed | 4789.0 docs/sec | ~0.2min remaining\n",
            "  70,000 processed | 4859.3 docs/sec | ~0.2min remaining\n",
            "  75,000 processed | 4933.2 docs/sec | ~0.1min remaining\n",
            "  80,000 processed | 4946.8 docs/sec | ~0.1min remaining\n",
            "  85,000 processed | 4928.3 docs/sec | ~0.1min remaining\n",
            "  90,000 processed | 4998.6 docs/sec | ~0.1min remaining\n",
            "  95,000 processed | 5076.0 docs/sec | ~0.1min remaining\n",
            "  100,000 processed | 5148.0 docs/sec | ~0.1min remaining\n",
            "  105,000 processed | 5220.1 docs/sec | ~0.0min remaining\n",
            "  110,000 processed | 5254.7 docs/sec | ~0.0min remaining\n",
            "  115,000 processed | 5190.1 docs/sec | ~0.0min remaining\n",
            "Patristic complete: 115,655 documents in 22.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_output = '/content/combined_normalized.json'\n",
        "\n",
        "with open(combined_output, 'w', encoding='utf-8') as f_out:\n",
        "    # Copy Bullinger\n",
        "    with open(bullinger_output, 'r', encoding='utf-8') as f_in:\n",
        "        for line in f_in:\n",
        "            f_out.write(line)\n",
        "\n",
        "    # Copy Patristic\n",
        "    with open(patristic_output, 'r', encoding='utf-8') as f_in:\n",
        "        for line in f_in:\n",
        "            f_out.write(line)\n",
        "\n",
        "# Check file size\n",
        "size_mb = os.path.getsize(combined_output) / (1024*1024)\n",
        "print(f\"Combined file created: {combined_output}\")\n",
        "print(f\"  Size: {size_mb:.1f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrC5jbwWFlDK",
        "outputId": "67390df7-2db5-41bb-e3a8-d6ac6a070f05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined file created: /content/combined_normalized.json\n",
            "  Size: 294.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!passim /content/combined_normalized.json /content/output_passim_normalized \\\n",
        "  --fields corpus \\\n",
        "  --filterpairs \"corpus != corpus2\" \\\n",
        "  -n 25 -m 15 -g 20 -a 20 --pcopy 0.3"
      ],
      "metadata": {
        "id": "dFVFsBLau217"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}